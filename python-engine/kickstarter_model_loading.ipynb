{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kickstarter Notebook for  Trained Models Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we must import the libraries once again since we haven't imported them in this file\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model\\kickstarter_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only the model weights\n",
    "new_model.save_weights('kickstarter_v1_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a temporary variable npz, where we will store each of the three Audiobooks datasets\n",
    "npz = np.load('kickstarter_data_train.npz')\n",
    "\n",
    "# we extract the inputs using the keyword under which we saved them\n",
    "# to ensure that they are all floats, let's also take care of that\n",
    "train_inputs = npz['inputs'].astype(np.float)\n",
    "# targets must be int because of sparse_categorical_crossentropy (we want to be able to smoothly one-hot encode them)\n",
    "train_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "# we load the validation data in the temporary variable\n",
    "npz = np.load('kickstarter_data_validation.npz')\n",
    "# we can load the inputs and the targets in the same line\n",
    "validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "# we load the test data in the temporary variable\n",
    "npz = np.load('kickstarter_data_test.npz')\n",
    "# we create 2 variables that will contain the test inputs and the test targets\n",
    "test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-60181c3a7fd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   1300\u001b[0m     \"\"\"\n\u001b[0;32m   1301\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   1303\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "26454/26454 [==============================] - 1s 37us/sample - loss: 0.0520 - accuracy: 0.9842\nRestored model, accuracy: 98.42%\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Evaluate the restored model\n",
    "test_loss, test_accuracy = new_model.evaluate(test_inputs, test_targets)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100*test_accuracy))\n",
    "\n",
    "prediction = new_model.predict(test_inputs[:100,:])\n",
    "rounded = np.round_(prediction)\n",
    "rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1, 23)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "test_inputs[:1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bittfcondacb9473150141438aac76f616c90c56d5",
   "display_name": "Python 3.7.7 64-bit ('tf': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}